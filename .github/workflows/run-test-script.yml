name: Test

on:
  workflow_dispatch:

jobs:
  build-and-run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # Cache Hugging Face models (modificato per josty11/distil2)
      - name: Cache Huggingface models
        uses: actions/cache@v3
        with:
          path: ~/.cache/huggingface
          key: ${{ runner.os }}-hf-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-hf-

      # Cache pip packages
      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Upgrade pip, setuptools, wheel
        run: python -m pip install --upgrade pip setuptools wheel

      - name: Install Python dependencies
        run: |
          python -m pip install --no-cache-dir "numpy<2"
          python -m pip install --no-cache-dir protobuf==3.20.3
          python -m pip install --no-cache-dir torch==2.0.1+cpu -f https://download.pytorch.org/whl/torch_stable.html
          python -m pip install --no-cache-dir transformers==4.33.2 sentencepiece

      # Pre-download e cache del modello josty11/distil2
      - name: Pre-download josty11/distil2 model
        run: |
          python -c "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM; \
          AutoTokenizer.from_pretrained('josty11/distil2'); \
          AutoModelForSeq2SeqLM.from_pretrained('josty11/distil2')"

      - name: Run prediction script
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: python scripts/test.py
